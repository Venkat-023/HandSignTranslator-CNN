Real-Time American Sign Language (ASL) Recognition Using CNN

HandSign-Translator is a real-time ASL alphabet recognition system that detects hand gestures from a webcam feed, classifies them using a custom-built Convolutional Neural Network (CNN), and dynamically constructs sentences based on confident predictions. The result is a smooth and intelligent system that bridges visual language and readable text.

ğŸ“Œ Project Highlights
ğŸ§  Custom CNN architecture built from scratch

ğŸ¥ Real-time gesture recognition via webcam

âœ‹ MediaPipe used for precise hand detection and dataset cleaning

âšª Grayscale image processing for faster and more robust model inference

ğŸ§ª Trained on a self-curated dataset with over 94% testing accuracy

ğŸ’¬ Confidence-based sentence construction displayed live on-screen

ğŸ–¼ï¸ Dataset Preparation
Source: ASL alphabet dataset from Kaggle

Due to dataset size and noise, it was split and preprocessed in parts

MediaPipe was used to extract and crop only the hand region from images

Cleaned dataset was saved and converted to grayscale for better model performance

Final dataset was significantly smaller, cleaner, and optimized for CNN training

ğŸ§  Model Architecture
Designed and trained 15+ custom CNN models

Used TensorFlow/Keras for model building and evaluation

Best-performing model achieved 94%+ accuracy on test data

Final model was exported and integrated into a real-time prediction pipeline

ğŸ¥ Real-Time Pipeline
Capture live video input using OpenCV

Detect hand region using MediaPipe

Preprocess the frame (resize & grayscale)

Predict gesture using the trained CNN

Validate prediction confidence

Build sentence from validated predictions

Display the result live on the webcam feed

âš™ï¸ Technologies Used
Python 3.x

TensorFlow / Keras

OpenCV

MediaPipe

NumPy, Matplotlib

ğŸ“¦ Use Cases
ASL learning tools and educational platforms

Assistive communication for individuals with speech or hearing impairments

Research in gesture recognition and HCI (Human-Computer Interaction)

Gesture-based user interfaces and control systems

ğŸ¯ Future Enhancements
Extend support to ASL words and phrases

Add multi-hand support for more complex gestures

Improve UI/UX with overlay controls and customization

Export as a lightweight desktop app using PyInstaller or Electron

